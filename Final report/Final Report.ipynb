{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting marginal electricity generation from power plants in ERCOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "- [Background](#Background)  \n",
    "- [Data collection](#Data-collection)  \n",
    "- [Data cleaning/merging](#Data-cleaning/merging)  \n",
    "    - [ERCOT data](#ERCOT-data)  \n",
    "    - [EIA data](#EIA-data)  \n",
    "        - [Power plant generation and fuel data from EIA-923](#Power-plant-generation-and-fuel-data-from-EIA-923)  \n",
    "        - [Power plant capacity from EIA-860](#Power-plant-capacity-from-EIA-860)  \n",
    "    - [EPA data](#EPA-data)  \n",
    "- [Merging data for clustering](#Merging-data-for-clustering)  \n",
    "- [Clustering](#Clustering)\n",
    "- [Calculating hourly generation change](#Calculating-hourly-generation-change)  \n",
    "- [Model training](#Model-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Most dispatchable electricity - electricity that can be produced on-demand - in the U.S. is generated at fossil power plants[[1]](#References). The plant, or plants, that generate more electricity in response to increased demand are called marginal generating units (MGUs). Models that predict MGUs generally fall into one of two categories: regression-based or unit-commitment economic dispatch[[2]](#References). The first category can account for effects (e.g. imperfect information) that are ignored in the second by examining real-world behavior. However, models that simply regress on historical behavior are ill-suited to making predictions about future grid conditions that differ from the data they were trained on. Applying machine learning techniques to energy sector analyses represents a pathway for potential improvements in the prediction of MGU behavior, and understanding the environmental impacts of energy transitions. This area of research is especially important as researchers and policy makers try to predict the economic and environmental impacts of vehicle electrification, demand-response management, and large scale deployment of variable renewable generating sources like wind and solar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to build a model that can predict the type of fossil MGU that will provide electricity for additional demand when given the current set of grid conditions. This type of problem can be difficult to solve, especially when the model is also trying to predict grid conditions like demand or wind generation. We are simplifying the model by treating these inputs as exogenous - the time of day or day of the year doesn't matter.\n",
    "\n",
    "Predicting which individual power plant will provide marginal generation under a given set of grid conditions is also difficult. Individual facilities might go down for maintanence or otherwise not respond to changing grid conditions in an expected manner. We group individual fossil power plants based on their historical operating characteristics (average heat rate, capacity, capacity factor, and 95th percentile 1-hour ramp rate) using k-means clustering. The model treats each group as a single generating unit, and predicts it's change in generation given a change in grid demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "Our dataset covers 9 years of operation in the ERCOT power grid, which covers most of Texas. Data sources include:\n",
    "\n",
    "- ERCOT [[3]](#References)\n",
    "    - Hourly demand for power in Megawatts (MW)\n",
    "    - Hourly generation of wind power and total installed capacity (MW)\n",
    "- Energy Information Agency (EIA)\n",
    "    - Annual generation for each power plant (MWh) and fuels used for generation [[4]](#References)\n",
    "    - Capacity of each power plant in a given year (MW) [[5]](#References)\n",
    "    - Monthly natural gas prices for electric customers in Texas [[6]](#References)\n",
    "    - Quarterly coal prices for electric consumers in Texas [[7]](#References)\n",
    "- Environmental Protection Agency (EPA)\n",
    "    - Hourly gross generation at fossil-fuel power plants larger than 25 MW [[8]](#References)\n",
    "\n",
    "All datasets were downloaded as Excel or CSV files. All of the raw data files combined are larger than 1 GB, and can be found on the [GitHub repository](https://github.com/gschivley/ERCOT_power) for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning/merging\n",
    "Because the datasets in this project came from a number of different sources and are given on a wide range of time scales, each had to be loaded, cleaned, and put in the correct form before they could all be merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ERCOT data\n",
    "ERCOT hourly data on demand (load), wind generation, and wind capacity can be downloaded for a full year in a single Excel file. File extensions include both .xls and .xlsx. The 9 files did not have consistent column names across all years. Changes were made by hand in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set up all the file paths, and column names to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'ERCOT/Hourly wind generation'\n",
    "full_xls = os.path.join(path, '*.xls')\n",
    "full_xlsx = os.path.join(path, '*.xlsx')\n",
    "\n",
    "files = glob.glob(full_xls)\n",
    "files.extend(glob.glob(full_xlsx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['ERCOT Load, MW', 'Total Wind Installed, MW',\n",
    "       'Total Wind Output, MW', 'Wind Output, % of Installed',\n",
    "       'Wind Output, % of Load', '1-hr MW change', '1-hr % change']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Read the excel files, combine them into a single dataframe, and only keep the columns we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ercot = pd.concat([pd.read_excel(fn, sn='numbers', index_col=0) for fn in files])\n",
    "ercot = ercot.loc[:,cols]\n",
    "ercot.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a few plots to ensure the data looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ercot.plot(y='Total Wind Installed, MW', use_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ercot.plot(y='ERCOT Load, MW', use_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EIA data\n",
    "We use EIA data for information about power plants and fuel prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Power plant generation and fuel data from EIA-923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the directory to find all the files to import\n",
    "#Modified so that it also works on macs\n",
    "path = os.path.join('EIA Data', '923-No_Header')\n",
    "full_path = os.path.join(path, '*.*')\n",
    "\n",
    "\n",
    "eiaNames = os.listdir(path)\n",
    "\n",
    "#Rename the keys for easier merging later\n",
    "fileNameMap = {'EIA923 SCHEDULES 2_3_4_5 Final 2010.xls':2010,\n",
    "                'EIA923 SCHEDULES 2_3_4_5 M Final 2009 REVISED 05252011.XLS':2009,\n",
    "                'eia923December2008.xls':2008,\n",
    "                'EIA923_Schedules_2_3_4_5_2011_Final_Revision.xlsx':2011,\n",
    "                'EIA923_Schedules_2_3_4_5_2012_Final_Release_12.04.2013.xlsx':2012,\n",
    "                'EIA923_Schedules_2_3_4_5_2013_Final_Revision.xlsx':2013,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2014_Final_Revision.xlsx':2014,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2015_Final.xlsx':2015,\n",
    "                'f906920_2007.xls':2007}\n",
    "\n",
    "#Load the files into data frames, one df per file\n",
    "eiaDict = {fileNameMap[fn]:pd.read_excel(os.path.join(path, fn)) for fn in eiaNames}\n",
    "eiaDict = {key:val[val[\"NERC Region\"] == \"TRE\"] for key, val in eiaDict.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Dict of values to replace to standardize column names across all dataframes\n",
    "monthDict = {\"JANUARY\":\"JAN\",\n",
    "           \"FEBRUARY\":\"FEB\",\n",
    "           \"MARCH\":\"MAR\",\n",
    "           \"APRIL\":\"APR\",\n",
    "           \"MAY\":\"MAY\",\n",
    "           \"JUNE\":\"JUN\",\n",
    "           \"JULY\":\"JUL\",\n",
    "           \"AUGUST\":\"AUG\",\n",
    "           \"SEPTEMBER\":\"SEP\",\n",
    "           \"OCTOBER\":\"OCT\",\n",
    "           \"NOVEMBER\":\"NOV\",\n",
    "           \"DECEMBER\":\"DEC\"}\n",
    "           \n",
    "replaceDict = {\"ELECTRIC\":\"ELEC\",\n",
    "               \"&\":\"AND\",\n",
    "               \"I.D.\":\"ID\",\n",
    "               \"MMBTUPER\":\"MMBTU_PER\"}\n",
    "               \n",
    "#Add \"MMBTUMON\" : \"MMBTU_MON\" to be replaced\n",
    "for month in monthDict.values():\n",
    "    replaceDict[\"MMBTU\"+month] = \"MMBTU_\" + month\n",
    "\n",
    "#Replace the column name\n",
    "def rename(col):\n",
    "    for old, new in monthDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    for old, new in replaceDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    col = col.replace(\"MMBTUS\", \"MMBTU\")\n",
    "    return col\n",
    "    \n",
    "#Iterate through each column name of each dataframe to standardize\n",
    "for key, df in eiaDict.iteritems():\n",
    "    colNames = [name.replace(\"\\n\", \"_\").replace(\" \", \"_\").strip().upper() for name in df.columns]\n",
    "    colNames = [rename(col) for col in colNames]\n",
    "    eiaDict[key].columns = colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Define the columns that are necessary but are not summable\n",
    "allCols = eiaDict[fileNameMap.values()[0]].columns\n",
    "nonSumCols = [\"PLANT_ID\", \"PLANT_NAME\", \"YEAR\"]\n",
    "\n",
    "#Define the columns that contain the year's totals (Used to calc fuel type %)\n",
    "yearCols = [\"TOTAL_FUEL_CONSUMPTION_QUANTITY\", \"ELEC_FUEL_CONSUMPTION_QUANTITY\",\n",
    "            \"TOTAL_FUEL_CONSUMPTION_MMBTU\", \"ELEC_FUEL_CONSUMPTION_MMBTU\",\n",
    "            \"NET_GENERATION_(MEGAWATTHOURS)\"]\n",
    "\n",
    "\n",
    "#Define the columns that are necessary and summable\n",
    "sumCols = []\n",
    "sumCols.extend(yearCols)\n",
    "# regex = re.compile(r\"^ELEC_QUANTITY_.*\")\n",
    "# sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^MMBTU_PER_UNIT_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^TOT_MMBTU_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^ELEC_MMBTUS_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^NETGEN_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get a list of all the different fuel type codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fuelTypes = []\n",
    "fuelTypes.extend([fuelType for df in eiaDict.values() for fuelType in df[\"REPORTED_FUEL_TYPE_CODE\"].tolist()])\n",
    "fuelTypes = set(fuelTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "EIA-923 splits out electricity generated at a power plant generating units and the type of fuel. We are aggregating everything to the facility level and assigning a single fuel type to the plant. This fuel type is used to filter out non-fossil plants and for analysis of what types of power plants are in the clusters.\n",
    "\n",
    "Three parts to aggregate by facility, and to calculate the % of each type of fuel. This will take a few minutes to run.  \n",
    "\n",
    "The end result is aggEIADict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Actually calculate the % fuel type for each facility grouping\n",
    "def calcPerc(group, aggGroup, fuelType, col):\n",
    "    #Check to see if the facility has a record for the fuel type, and if the total column > 0\n",
    "    if len(group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType]) > 0 and aggGroup[col] > 0:\n",
    "        #summing fuel type because a facility may have multiple plants with the same fuel type        \n",
    "        return float((group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType][col]).sum())/aggGroup[col] \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Perform the aggregation on facility level\n",
    "def aggAndCalcPerc(group):\n",
    "    aggGroup = group.iloc[0][nonSumCols] #Get the non-agg columns\n",
    "    aggGroup = aggGroup.append(group[sumCols].sum())   #Aggregate the agg columns and append to non-agg\n",
    "    percCols = {col + \" %\" + fuelType:calcPerc(group, aggGroup, fuelType, col) for col in yearCols for fuelType in fuelTypes}\n",
    "    aggGroup = aggGroup.append(pd.Series(percCols))\n",
    "    return aggGroup    \n",
    "\n",
    "#Iterate through each dataframe to perform aggregation by facility\n",
    "aggEIADict = dict()\n",
    "for key, df in eiaDict.iteritems():\n",
    "    gb = df.groupby(by=\"PLANT_ID\")\n",
    "    #aggGroup will be a list of panda series, each series representing a facility\n",
    "    aggGroup = [aggAndCalcPerc(gb.get_group(group)) for group in gb.groups]\n",
    "    aggEIADict[key] = pd.DataFrame(aggGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Combine all df's from the dict into one df**\n",
    "\n",
    "Concat all dataframes, reset the index, determine the primary fuel type for each facility, filter to only include fossil power plants, and export as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all923 = pd.concat(aggEIADict)\n",
    "all923.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def top_fuel(row):\n",
    "    #Fraction of largest fuel for electric heat input \n",
    "    try:\n",
    "        fuel = row.iloc[1:27].idxmax()[29:]\n",
    "    except:\n",
    "        return None\n",
    "    return fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all923['FUEL'] = all923.apply(top_fuel, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Because the EPA data only includes power plants that burn fossil fuels, we are only keeping these facilities. The codes below correspond to:\n",
    "- Diesel fuel oil\n",
    "- Lignite coal\n",
    "- Natural gas\n",
    "- Petroleum coke\n",
    "- Subbituminous coal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fossil923 = all923.loc[all923['FUEL'].isin(['DFO', 'LIG', 'NG', 'PC', 'SUB'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power plant capacity from EIA-860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through the directory to find all the files to import\n",
    "path = os.path.join('EIA Data', '860-No_Header')\n",
    "full_path = os.path.join(path, '*.*')\n",
    "\n",
    "eia860Names = os.listdir(path)\n",
    "\n",
    "# Rename the keys for easier merging later\n",
    "fileName860Map = {  'GenY07.xls':2007,\n",
    "                    'GenY08.xls':2008,\n",
    "                    'GeneratorY09.xls':2009,\n",
    "                    'GeneratorsY2010.xls':2010,\n",
    "                    'GeneratorY2011.xlsx':2011,\n",
    "                    'GeneratorY2012.xlsx':2012,\n",
    "                    '3_1_Generator_Y2013.xlsx':2013,\n",
    "                    '3_1_Generator_Y2014.xlsx':2014,\n",
    "                    '3_1_Generator_Y2015.xlsx':2015}\n",
    "\n",
    "#Load the files into data frames, one df per file\n",
    "eia860Dict = {fileName860Map[fn]:pd.read_excel(os.path.join(path, fn)) for fn in eia860Names}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dict of values to replace to standardize column names across all dataframes\n",
    "renameDict = {  \"PLNTCODE\":\"PLANT_ID\",\n",
    "                \"PLANT_CODE\":\"PLANT_ID\",\n",
    "                \"Plant Code\":\"PLANT_ID\",\n",
    "                \"NAMEPLATE\":\"NAMEPLATE_CAPACITY(MW)\",\n",
    "                \"Nameplate Capacity (MW)\":\"NAMEPLATE_CAPACITY(MW)\"}\n",
    "\n",
    "#Replace the column name\n",
    "def rename860(col):\n",
    "    for old, new in renameDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "    return col\n",
    "\n",
    "#Iterate through each column name of each dataframe to standardize and select columns 'PLANT_ID', 'NAMEPLATE_CAPACITY(MW)'\n",
    "for key, df in eia860Dict.iteritems():\n",
    "    colNames = [rename860(col) for col in df.columns]\n",
    "    eia860Dict[key].columns = colNames\n",
    "    eia860Dict[key] = eia860Dict[key][[\"PLANT_ID\", \"NAMEPLATE_CAPACITY(MW)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power plants can include multiple generating units. We are aggregating the total generating capacity of units in the EIA-860 database to the facility level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each dataframe to perform aggregation by PLANT_ID\n",
    "for key, df in eia860Dict.iteritems():\n",
    "    gb = df.groupby(by='PLANT_ID').apply(lambda x: x['NAMEPLATE_CAPACITY(MW)'].sum())\n",
    "    eia860Dict[key]['NAMEPLATE_CAPACITY(MW)'] = eia860Dict[key].PLANT_ID.apply(gb.get_value)\n",
    "    eia860Dict[key] = eia860Dict[key].drop_duplicates(subset=['PLANT_ID', 'NAMEPLATE_CAPACITY(MW)'])\n",
    "    eia860Dict[key] = eia860Dict[key].sort_values(by='PLANT_ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuel price data\n",
    "**Need to decide what level of merging to include in this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with natural gas price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('EIA data', 'Natural gas price', 'N3045TX3m.xls')\n",
    "ng_price = pd.read_excel(path, sheetname='Data 1', header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_price.rename(columns={\"Texas Natural Gas Price Sold to Electric Power Consumers (Dollars per Thousand Cubic Feet)\":\n",
    "                         \"NG Price ($/mcf)\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_price.loc[:,'Month'] = ng_price.loc[:,'Date'].apply(lambda x: x.month)\n",
    "ng_price.loc[:,'Year'] = ng_price.loc[:,'Date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join('EIA data', 'Coal prices', 'Texas electric sector coal price.xlsx')\n",
    "coal_temp = pd.read_excel(path, sheetname='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPA data\n",
    "EPA hourly data is stored in a series of .txt files that each cover a 6 month period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the EPA files into a dataframe\n",
    "path2 = os.path.join('EPA air markets')\n",
    "epaNames = os.listdir(path2)\n",
    "filePaths = {dn:os.path.join(path2, dn, \"*.txt\") for dn in epaNames}\n",
    "filePaths = {dn:glob.glob(val) for dn, val in filePaths.iteritems()}\n",
    "epaDict = {key:pd.read_csv(fp, index_col = False) for key, val in filePaths.iteritems() for fp in val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrames in epaDict contain all power plants in Texas. We can filter on NERC REGION so that it only includes ERCOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the column names to remove the leading space.\n",
    "for key, df in epaDict.iteritems():\n",
    "    colNames = [name.upper().strip() for name in df.columns]\n",
    "    colNames[colNames.index(\"FACILITY ID (ORISPL)\")] = \"PLANT_ID\"\n",
    "    epaDict[key].columns = colNames\n",
    "    \n",
    "#Convert DATE to datetime object\n",
    "#Add new column DATETIME with both date and hour\n",
    "for key, df in epaDict.iteritems():\n",
    "    epaDict[key][\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    epaDict[key]['DATETIME'] = df['DATE'] + pd.to_timedelta(df['HOUR'], unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Boolean filter to only keep ERCOT plants\n",
    "for key, df in epaDict.iteritems():\n",
    "    epaDict[key] = df[df[\"NERC REGION\"] == \"ERCOT\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterDict = dict()\n",
    "for key, df in eia860Dict.iteritems():\n",
    "    clusterDict[key] = pd.merge(aggEIADict[key], eia860Dict[key], how='left', on='PLANT_ID')[['PLANT_ID', 'NAMEPLATE_CAPACITY(MW)']]\n",
    "    clusterDict[key].rename(columns={'NAMEPLATE_CAPACITY(MW)': 'capacity', 'PLANT_ID': 'plant_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_fuel(row):\n",
    "    #Fraction of largest fuel for electric heat input \n",
    "    try:\n",
    "        fuel = row.idxmax()[29:]\n",
    "    except:\n",
    "        return None\n",
    "    return fuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Capacity factor, Efficiency, Fuel type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, df in clusterDict.iteritems():\n",
    "    clusterDict[key]['year'] = key\n",
    "    clusterDict[key]['capacity_factor'] = aggEIADict[key]['NET_GENERATION_(MEGAWATTHOURS)'] / (8670*clusterDict[key]['capacity'])\n",
    "    clusterDict[key]['efficiency'] = (aggEIADict[key]['NET_GENERATION_(MEGAWATTHOURS)']*3.412)/(1.0*aggEIADict[key]['ELEC_FUEL_CONSUMPTION_MMBTU'])\n",
    "    clusterDict[key]['fuel_type'] = aggEIADict[key][fuel_cols].apply(top_fuel, axis=1)\n",
    "    clusterDict[key] = clusterDict[key][clusterDict[key]['fuel_type'].isin(['SUB', \n",
    "                                                                            'LIG', \n",
    "                                                                            'DFO',\n",
    "                                                                            'NG', \n",
    "                                                                            'PC'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all EPA files in one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['PLANT_ID', 'YEAR', 'DATE', 'HOUR', 'GROSS LOAD (MW)']\n",
    "counter = 0\n",
    "for key, df in epaDict.iteritems():\n",
    "    if counter == 0:\n",
    "        result = epaDict[key][columns]\n",
    "        counter = 1\n",
    "    else:\n",
    "        result = result.append(epaDict[key][columns], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the ramp rate for every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plant_gen_delta(df):\n",
    "    \"\"\"\n",
    "    For every plant in the input df, calculate the change in gross load (MW)\n",
    "    from the previous hour.\n",
    "    \n",
    "    input:\n",
    "        df: dataframe of EPA clean air markets data\n",
    "    return:\n",
    "        df: concatanated list of dataframes\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for plant in df['PLANT_ID'].unique():\n",
    "        temp = df.loc[df['PLANT_ID'] == plant,:]\n",
    "        gen_change = temp.loc[:,'GROSS LOAD (MW)'].values - temp.loc[:,'GROSS LOAD (MW)'].shift(1).values\n",
    "        temp.loc[:,'Gen Change'] = gen_change\n",
    "        df_list.append(temp)\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ramp_df = plant_gen_delta(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the 95th percentile ramp rate for each plant in each year. We use the 95th percentile to avoid data errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['PLANT_ID', 'YEAR', 'Gen Change']\n",
    "\n",
    "ramp_rate_list = []\n",
    "for year in ramp_df['YEAR'].unique():\n",
    "    for plant in ramp_df.loc[ramp_df['YEAR']==year,'PLANT_ID'].unique():\n",
    "        # 95th percentile ramp rate per plant per year\n",
    "        ramp_95 = ramp_df.loc[(ramp_df['PLANT_ID']== plant) & \n",
    "                              (ramp_df['YEAR']==year),'Gen Change'].quantile(0.95, interpolation='nearest')\n",
    "        ramp_rate_list.append([plant, year, ramp_95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the EIA data (clusterDict) with the ramp rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, df in clusterDict.iteritems():\n",
    "    clusterDict[key] = pd.merge(clusterDict[key], ramp_rate_df, how='left', on=['plant_id', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses the class `Clusters`, which is defined in `cluster.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cluster import Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now `Clusters` reads the data in from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'Cluster_Data_2.csv'\n",
    "path = '../Clean Data'\n",
    "fullpath = os.path.join(path, filename)\n",
    "cluster = Clusters(fullpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_clusters()` function uses KMeans from scikit-learn to produce clusters across a range of k-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.make_clusters(n_clusters=range(4,26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evaluate_clusters()` calculates and plots the calinski-harabaz score and silhouette score for each k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.evaluate_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figures above, it is difficult to determine an optimal number of clusters. The silhouette score clearly shows that we need more than 5 clusters. 6 looks like a good number, but we also look at 12 to see if it will provide a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_plants = cluster.label_and_export(k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating hourly generation change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Siler-Evans, K., Azevedo, I. L., & Morgan, M. G. (2012). Marginal Emissions Factors for the U.S. Electricity System. Environmental Science & Technology, 46(9), 4742–4748.\n",
    "2. Graff Zivin, J. S., Kotchen, M. J. & Mansur, E. T. Spatial and temporal heterogeneity of marginal emissions: Implications for electric cars and other electricity-shifting policies. Journal of Economic Behavior & Organization 107, Part A, 248–268 (2014).\n",
    "3. http://www.ercot.com/gridinfo/generation\n",
    "4. https://www.eia.gov/electricity/data/eia923/\n",
    "5. https://www.eia.gov/electricity/data/eia860/\n",
    "6. http://www.eia.gov/dnav/ng/hist/n3045tx3m.htm\n",
    "7. [EIA Coal Data Browser](http://www.eia.gov/beta/coal/data/browser/#/topic/45?agg=1,0&geo=vvvvvvvvvvvvo&rank=l&linechart=~~COAL.SHIP_PLANT_PRICE.TX-LIG.Q~COAL.SHIP_PLANT_PRICE.TX-SUB.Q&columnchart=COAL.SHIP_PLANT_PRICE.US-TOT.Q&map=COAL.SHIP_PLANT_PRICE.US-TOT.Q&freq=Q&start=200801&end=201601&chartindexed=0&ctype=linechart&ltype=pin&rtype=s&maptype=0&rse=0&pin=)\n",
    "8. https://ampd.epa.gov/ampd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
