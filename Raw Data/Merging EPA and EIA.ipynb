{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the EIA Data, the path may need to be updated...\n",
    "This will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Iterate through the directory to find all the files to import\n",
    "#Modified so that it also works on macs\n",
    "path = os.path.join('EIA Data', '923-No_Header')\n",
    "full_path = os.path.join(path, '*.*')\n",
    "\n",
    "\n",
    "eiaNames = os.listdir(path)\n",
    "\n",
    "#Rename the keys for easier merging later\n",
    "fileNameMap = {'EIA923 SCHEDULES 2_3_4_5 Final 2010.xls':2010,\n",
    "                'EIA923 SCHEDULES 2_3_4_5 M Final 2009 REVISED 05252011.XLS':2009,\n",
    "                'eia923December2008.xls':2008,\n",
    "                'EIA923_Schedules_2_3_4_5_2011_Final_Revision.xlsx':2011,\n",
    "                'EIA923_Schedules_2_3_4_5_2012_Final_Release_12.04.2013.xlsx':2012,\n",
    "                'EIA923_Schedules_2_3_4_5_2013_Final_Revision.xlsx':2013,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2014_Final_Revision.xlsx':2014,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2015_Final.xlsx':2015,\n",
    "                'f906920_2007.xls':2007}\n",
    "\n",
    "#Load the files into data frames, one df per file\n",
    "eiaDict = {fileNameMap[fn]:pd.read_excel(os.path.join(path, fn)) for fn in eiaNames}\n",
    "eiaDict = {key:val[val[\"NERC Region\"] == \"TRE\"] for key, val in eiaDict.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The excel documents have different column names so we need to standardize them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dict of values to replace to standardize column names across all dataframes\n",
    "monthDict = {\"JANUARY\":\"JAN\",\n",
    "           \"FEBRUARY\":\"FEB\",\n",
    "           \"MARCH\":\"MAR\",\n",
    "           \"APRIL\":\"APR\",\n",
    "           \"MAY\":\"MAY\",\n",
    "           \"JUNE\":\"JUN\",\n",
    "           \"JULY\":\"JUL\",\n",
    "           \"AUGUST\":\"AUG\",\n",
    "           \"SEPTEMBER\":\"SEP\",\n",
    "           \"OCTOBER\":\"OCT\",\n",
    "           \"NOVEMBER\":\"NOV\",\n",
    "           \"DECEMBER\":\"DEC\"}\n",
    "           \n",
    "replaceDict = {\"ELECTRIC\":\"ELEC\",\n",
    "               \"&\":\"AND\",\n",
    "               \"I.D.\":\"ID\",\n",
    "               \"MMBTUPER\":\"MMBTU_PER\"}\n",
    "               \n",
    "#Add \"MMBTUMON\" : \"MMBTU_MON\" to be replaced\n",
    "for month in monthDict.values():\n",
    "    replaceDict[\"MMBTU\"+month] = \"MMBTU_\" + month\n",
    "\n",
    "#Replace the column name\n",
    "def rename(col):\n",
    "    for old, new in monthDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    for old, new in replaceDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    col = col.replace(\"MMBTUS\", \"MMBTU\")\n",
    "    return col\n",
    "    \n",
    "#Iterate through each column name of each dataframe to standardize\n",
    "for key, df in eiaDict.iteritems():\n",
    "    colNames = [name.replace(\"\\n\", \"_\").replace(\" \", \"_\").strip().upper() for name in df.columns]\n",
    "    colNames = [rename(col) for col in colNames]\n",
    "    eiaDict[key].columns = colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which columns we need to sum, and which columns don't need to be summed, but we still need to keep.\n",
    "\n",
    "Note: If we don't care about monthly stuff we can delete the second block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allCols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-035d1d317d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msumCols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myearCols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^ELEC_QUANTITY_.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msumCols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallCols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^MMBTU_PER_UNIT_.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msumCols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallCols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allCols' is not defined"
     ]
    }
   ],
   "source": [
    "#Define the columns that contain the year's totals (Used to calc fuel type %)\n",
    "yearCols = [\"TOTAL_FUEL_CONSUMPTION_QUANTITY\", \"ELEC_FUEL_CONSUMPTION_QUANTITY\",\n",
    "            \"TOTAL_FUEL_CONSUMPTION_MMBTU\", \"ELEC_FUEL_CONSUMPTION_MMBTU\",\n",
    "            \"NET_GENERATION_(MEGAWATTHOURS)\"]\n",
    "\n",
    "\n",
    "#Define the columns that are necessary and summable\n",
    "sumCols = []\n",
    "sumCols.extend(yearCols)\n",
    "regex = re.compile(r\"^ELEC_QUANTITY_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^MMBTU_PER_UNIT_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^TOT_MMBTU_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^ELEC_MMBTUS_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^NETGEN_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaced `allCols` with `yearCols`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the columns that contain the year's totals (Used to calc fuel type %)\n",
    "yearCols = [\"TOTAL_FUEL_CONSUMPTION_QUANTITY\", \"ELEC_FUEL_CONSUMPTION_QUANTITY\",\n",
    "            \"TOTAL_FUEL_CONSUMPTION_MMBTU\", \"ELEC_FUEL_CONSUMPTION_MMBTU\",\n",
    "            \"NET_GENERATION_(MEGAWATTHOURS)\"]\n",
    "\n",
    "\n",
    "#Define the columns that are necessary and summable\n",
    "sumCols = []\n",
    "sumCols.extend(yearCols)\n",
    "regex = re.compile(r\"^ELEC_QUANTITY_.*\")\n",
    "sumCols.extend([col for col in yearCols if regex.search(col)])\n",
    "regex = re.compile(r\"^MMBTU_PER_UNIT_.*\")\n",
    "sumCols.extend([col for col in yearCols if regex.search(col)])\n",
    "regex = re.compile(r\"^TOT_MMBTU_.*\")\n",
    "sumCols.extend([col for col in yearCols if regex.search(col)])\n",
    "regex = re.compile(r\"^ELEC_MMBTUS_.*\")\n",
    "sumCols.extend([col for col in yearCols if regex.search(col)])\n",
    "regex = re.compile(r\"^NETGEN_.*\")\n",
    "sumCols.extend([col for col in yearCols if regex.search(col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all the different fuel type codes.  If we don't care about all of them, then just hardcode the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fuelTypes = []\n",
    "fuelTypes.extend([fuelType for df in eiaDict.values() for fuelType in df[\"REPORTED_FUEL_TYPE_CODE\"].tolist()])\n",
    "fuelTypes = set(fuelTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'AB',\n",
       " u'BIT',\n",
       " u'BLQ',\n",
       " u'DFO',\n",
       " u'JF',\n",
       " u'LFG',\n",
       " u'LIG',\n",
       " u'MWH',\n",
       " u'NG',\n",
       " u'NUC',\n",
       " u'OBG',\n",
       " u'OBL',\n",
       " u'OBS',\n",
       " u'OG',\n",
       " u'OTH',\n",
       " u'PC',\n",
       " u'PUR',\n",
       " u'RFO',\n",
       " u'SC',\n",
       " u'SUB',\n",
       " u'SUN',\n",
       " u'WAT',\n",
       " u'WDS',\n",
       " u'WH',\n",
       " u'WND',\n",
       " u'WO'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuelTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 parts to aggregate by facility, and to calculate the % of each type of fuel.  This will take a few minutes to run.\n",
    "\n",
    "The end result is aggEIADict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'nonSumCols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-090b63278065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PLANT_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#aggGroup will be a list of panda series, each series representing a facility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0maggGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maggAndCalcPerc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0maggEIADict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-090b63278065>\u001b[0m in \u001b[0;36maggAndCalcPerc\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Perform the aggregation on facility level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maggAndCalcPerc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0maggGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnonSumCols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Get the non-agg columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0maggGroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msumCols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#Aggregate the agg columns and append to non-agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpercCols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" %\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfuelType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcalcPerc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuelType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myearCols\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfuelType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuelTypes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'nonSumCols' is not defined"
     ]
    }
   ],
   "source": [
    "#Actually calculate the % type for each facility grouping\n",
    "def calcPerc(group, aggGroup, fuelType, col):\n",
    "    #Check to see if the facility has a record for the fuel type, and if the total column > 0\n",
    "    if len(group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType]) > 0 and aggGroup[col] > 0:\n",
    "        #summing fuel type because a facility may have multiple plants with the same fuel type        \n",
    "        return float((group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType][col]).sum())/aggGroup[col] \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Perform the aggregation on facility level\n",
    "def aggAndCalcPerc(group):\n",
    "    aggGroup = group.iloc[0][nonSumCols] #Get the non-agg columns\n",
    "    aggGroup = aggGroup.append(group[sumCols].sum())   #Aggregate the agg columns and append to non-agg\n",
    "    percCols = {col + \" %\" + fuelType:calcPerc(group, aggGroup, fuelType, col) for col in yearCols for fuelType in fuelTypes}\n",
    "    aggGroup = aggGroup.append(pd.Series(percCols))\n",
    "    return aggGroup    \n",
    "\n",
    "#Iterate through each dataframe to perform aggregation by facility\n",
    "aggEIADict = dict()\n",
    "for key, df in eiaDict.iteritems():\n",
    "    gb = df.groupby(by=\"PLANT_ID\")\n",
    "    #aggGroup will be a list of panda series, each series representing a facility\n",
    "    aggGroup = [aggAndCalcPerc(gb.get_group(group)) for group in gb.groups]\n",
    "    aggEIADict[key] = pd.DataFrame(aggGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the EPA Data, the path may need to be updated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the EPA files into a dataframe\n",
    "path2 = os.path.join('EPA air markets')\n",
    "epaNames = os.listdir(path2)\n",
    "filePaths = {dn:os.path.join(path2, dn, \"*.txt\") for dn in epaNames}\n",
    "filePaths = {dn:glob.glob(val) for dn, val in filePaths.iteritems()}\n",
    "epaDict = {key:pd.read_csv(fp, index_col = False) for key, val in filePaths.iteritems() for fp in val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First rename the column name so we can merge on that column, then change the datatype of date to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the column names to remove the leading space.\n",
    "for key, df in epaDict.iteritems():\n",
    "    colNames = [name.upper().strip() for name in df.columns]\n",
    "    colNames[colNames.index(\"FACILITY ID (ORISPL)\")] = \"PLANT_ID\"\n",
    "    epaDict[key].columns = colNames\n",
    "    \n",
    "#Convert to datetime object\n",
    "for key, df in epaDict.iteritems():\n",
    "    epaDict[key][\"DATE\"] = pd.to_datetime(df[\"DATE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrames in `epaDict` contain all power plants in Texas. We can filter on `NERC REGION` so that it only includes ERCOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan, 'ERCOT', 'SERC', 'SPP', 'WECC'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(epaDict['2015 July-Dec'].loc[:,'NERC REGION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boolean filter to only keep ERCOT plants\n",
    "for key, df in epaDict.iteritems():\n",
    "    epaDict[key] = epaDict[key][epaDict[key].loc[:,'NERC REGION'] == 'ERCOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERCOT'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(epaDict['2015 July-Dec'].loc[:,'NERC REGION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally join the two data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join the two data sources on PLANT_ID\n",
    "fullData = {key:df.merge(aggEIADict[df[\"YEAR\"][0]], on=\"PLANT_ID\") for key, df in epaDict.iteritems()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
