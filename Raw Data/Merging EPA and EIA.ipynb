{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the EIA Data, the path may need to be updated...\n",
    "This will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the directory to find all the files to import\n",
    "path = \"ERCOT_power\\Raw Data\\EIA data\\923-No_Header\"\n",
    "eiaNames = os.listdir(path)\n",
    "\n",
    "#Rename the keys for easier merging later\n",
    "fileNameMap = {'EIA923 SCHEDULES 2_3_4_5 Final 2010.xls':2010,\n",
    "                'EIA923 SCHEDULES 2_3_4_5 M Final 2009 REVISED 05252011.XLS':2009,\n",
    "                'eia923December2008.xls':2008,\n",
    "                'EIA923_Schedules_2_3_4_5_2011_Final_Revision.xlsx':2011,\n",
    "                'EIA923_Schedules_2_3_4_5_2012_Final_Release_12.04.2013.xlsx':2012,\n",
    "                'EIA923_Schedules_2_3_4_5_2013_Final_Revision.xlsx':2013,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2014_Final_Revision.xlsx':2014,\n",
    "                'EIA923_Schedules_2_3_4_5_M_12_2015_Final.xlsx':2015,\n",
    "                'f906920_2007.xls':2007}\n",
    "\n",
    "#Load the files into data frames, one df per file\n",
    "eiaDict = {fileNameMap[fn]:pd.read_excel(os.path.join(path, fn)) for fn in eiaNames}\n",
    "eiaDict = {key:val[val[\"NERC Region\"] == \"TRE\"] for key, val in eiaDict.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The excel documents have different column names so we need to standardize them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dict of values to replace to standardize column names across all dataframes\n",
    "monthDict = {\"JANUARY\":\"JAN\",\n",
    "           \"FEBRUARY\":\"FEB\",\n",
    "           \"MARCH\":\"MAR\",\n",
    "           \"APRIL\":\"APR\",\n",
    "           \"MAY\":\"MAY\",\n",
    "           \"JUNE\":\"JUN\",\n",
    "           \"JULY\":\"JUL\",\n",
    "           \"AUGUST\":\"AUG\",\n",
    "           \"SEPTEMBER\":\"SEP\",\n",
    "           \"OCTOBER\":\"OCT\",\n",
    "           \"NOVEMBER\":\"NOV\",\n",
    "           \"DECEMBER\":\"DEC\"}\n",
    "           \n",
    "replaceDict = {\"ELECTRIC\":\"ELEC\",\n",
    "               \"&\":\"AND\",\n",
    "               \"I.D.\":\"ID\",\n",
    "               \"MMBTUPER\":\"MMBTU_PER\"}\n",
    "               \n",
    "#Add \"MMBTUMON\" : \"MMBTU_MON\" to be replaced\n",
    "for month in monthDict.values():\n",
    "    replaceDict[\"MMBTU\"+month] = \"MMBTU_\" + month\n",
    "\n",
    "#Replace the column name\n",
    "def rename(col):\n",
    "    for old, new in monthDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    for old, new in replaceDict.iteritems():\n",
    "        col = col.replace(old, new)\n",
    "        \n",
    "    col = col.replace(\"MMBTUS\", \"MMBTU\")\n",
    "    return col\n",
    "    \n",
    "#Iterate through each column name of each dataframe to standardize\n",
    "for key, df in eiaDict.iteritems():\n",
    "    colNames = [name.replace(\"\\n\", \"_\").replace(\" \", \"_\").strip().upper() for name in df.columns]\n",
    "    colNames = [rename(col) for col in colNames]\n",
    "    eiaDict[key].columns = colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which columns we need to sum, and which columns don't need to be summed, but we still need to keep.\n",
    "\n",
    "Note: If we don't care about monthly stuff we can delete the second block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the columns that contain the year's totals (Used to calc fuel type %)\n",
    "yearCols = [\"TOTAL_FUEL_CONSUMPTION_QUANTITY\", \"ELEC_FUEL_CONSUMPTION_QUANTITY\",\n",
    "            \"TOTAL_FUEL_CONSUMPTION_MMBTU\", \"ELEC_FUEL_CONSUMPTION_MMBTU\",\n",
    "            \"NET_GENERATION_(MEGAWATTHOURS)\"]\n",
    "\n",
    "\n",
    "#Define the columns that are necessary and summable\n",
    "sumCols = []\n",
    "sumCols.extend(yearCols)\n",
    "regex = re.compile(r\"^ELEC_QUANTITY_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^MMBTU_PER_UNIT_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^TOT_MMBTU_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^ELEC_MMBTUS_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])\n",
    "regex = re.compile(r\"^NETGEN_.*\")\n",
    "sumCols.extend([col for col in allCols if regex.search(col)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all the different fuel type codes.  If we don't care about all of them, then just hardcode the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fuelTypes = []\n",
    "fuelTypes.extend([fuelType for df in eiaDict.values() for fuelType in df[\"REPORTED_FUEL_TYPE_CODE\"].tolist()])\n",
    "fuelTypes = set(fuelTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 parts to aggregate by facility, and to calculate the % of each type of fuel.  This will take a few minutes to run.\n",
    "\n",
    "The end result is aggEIADict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Actually calculate the % type for each facility grouping\n",
    "def calcPerc(group, aggGroup, fuelType, col):\n",
    "    #Check to see if the facility has a record for the fuel type, and if the total column > 0\n",
    "    if len(group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType]) > 0 and aggGroup[col] > 0:\n",
    "        #summing fuel type because a facility may have multiple plants with the same fuel type        \n",
    "        return float((group[group[\"REPORTED_FUEL_TYPE_CODE\"] == fuelType][col]).sum())/aggGroup[col] \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Perform the aggregation on facility level\n",
    "def aggAndCalcPerc(group):\n",
    "    aggGroup = group.iloc[0][nonSumCols] #Get the non-agg columns\n",
    "    aggGroup = aggGroup.append(group[sumCols].sum())   #Aggregate the agg columns and append to non-agg\n",
    "    percCols = {col + \" %\" + fuelType:calcPerc(group, aggGroup, fuelType, col) for col in yearCols for fuelType in fuelTypes}\n",
    "    aggGroup = aggGroup.append(pd.Series(percCols))\n",
    "    return aggGroup    \n",
    "\n",
    "#Iterate through each dataframe to perform aggregation by facility\n",
    "aggEIADict = dict()\n",
    "for key, df in eiaDict.iteritems():\n",
    "    gb = df.groupby(by=\"PLANT_ID\")\n",
    "    #aggGroup will be a list of panda series, each series representing a facility\n",
    "    aggGroup = [aggAndCalcPerc(gb.get_group(group)) for group in gb.groups]\n",
    "    aggEIADict[key] = pd.DataFrame(aggGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the EPA Data, the path may need to be updated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the EPA files into a dataframe\n",
    "path2 = \"ERCOT_power\\Raw Data\\EPA air markets\"\n",
    "epaNames = os.listdir(path2)\n",
    "filePaths = {dn:os.path.join(path2, dn, \"*.txt\") for dn in epaNames}\n",
    "filePaths = {dn:glob.glob(val) for dn, val in filePaths.iteritems()}\n",
    "epaDict = {key:pd.read_csv(fp, index_col = False) for key, val in filePaths.iteritems() for fp in val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First rename the column name so we can merge on that column, then change the datatype of date to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the column names to remove the leading space.\n",
    "for key, df in epaDict.iteritems():\n",
    "    colNames = [name.upper().strip() for name in df.columns]\n",
    "    colNames[colNames.index(\"FACILITY ID (ORISPL)\")] = \"PLANT_ID\"\n",
    "    epaDict[key].columns = colNames\n",
    "    \n",
    "#Convert to datetime object\n",
    "for key, df in epaDict.iteritems():\n",
    "    epaDict[key][\"DATE\"] = pd.to_datetime(df[\"DATE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally join the two data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join the two data sources on PLANT_ID\n",
    "fullData = {key:df.merge(aggEIADict[df[\"YEAR\"][0]], on=\"PLANT_ID\") for key, df in epaDict.iteritems()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
